# ğŸ¤Ÿ Tradutor LIBRAS â€“ App Mobile de Acessibilidade

Aplicativo mobile que traduz **sinais da LÃ­ngua Brasileira de Sinais (LIBRAS)** capturados pela cÃ¢mera do celular em **texto** e **Ã¡udio** em tempo real, facilitando a comunicaÃ§Ã£o entre pessoas surdas/mudas e ouvintes.

---

## ğŸ“± Funcionalidades

- ğŸ“· Captura de sinais com a cÃ¢mera do celular
- ğŸ§  Reconhecimento de gestos utilizando IA (MediaPipe + TensorFlow)
- ğŸ“ ConversÃ£o de gestos em texto legÃ­vel
- ğŸ”Š Leitura em voz alta usando TTS (Text-to-Speech)
- âš™ï¸ ConfiguraÃ§Ãµes de idioma e voz
- ğŸ‘¥ InclusÃ£o e acessibilidade como foco principal

---

## ğŸ› ï¸ Tecnologias Utilizadas

### Front-end (Mobile)
- [React Native](https://reactnative.dev/)
- [Expo](https://expo.dev/)
- [React Navigation](https://reactnavigation.org/)
- [Expo Camera](https://docs.expo.dev/versions/latest/sdk/camera/)
- [expo-speech](https://docs.expo.dev/versions/latest/sdk/speech/)

### IA e Reconhecimento
- [MediaPipe Hands](https://developers.google.com/mediapipe)
- [TensorFlow / Keras](https://www.tensorflow.org/)
- [OpenCV (para prÃ©-processamento)](https://opencv.org/)

### Backend (opcional)
- Python + Flask/FastAPI (servindo o modelo de IA)
- TTS via Google Cloud, Amazon Polly ou ElevenLabs API

---

## ğŸ“‚ Estrutura do Projeto

'libras-translator-app/
â”œâ”€â”€ mobile/ # App mobile com React Native
â”‚ â”œâ”€â”€ App.js
â”‚ â”œâ”€â”€ screens/
â”‚ â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ services/
â”‚ â””â”€â”€ utils/
â”œâ”€â”€ backend-ia/ # API Python com IA (opcional)
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ models/
â”‚ â””â”€â”€ preprocessing/
â”œâ”€â”€ datasets/ # Dataset de sinais LIBRAS
â””â”€â”€ README.md'